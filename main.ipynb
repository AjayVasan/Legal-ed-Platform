{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, request, render_template, redirect, url_for, flash, session\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import re\n",
        "import random\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from datetime import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc1d9016",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ## Run the Application\n",
        "# !python -m pip install pytesseract\n",
        "# !py -m pip install pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Flask App\n",
        "\n",
        "In a Jupyter notebook environment, we'll still define the Flask app but we won't run it directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "app.secret_key = 'legal_education_platform_secret'  # Secret key for flash messages and sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Pre-trained Models\n",
        "\n",
        "We'll load the NLP models from Hugging Face's transformers library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained models from Hugging Face\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "ner_tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "ner_model = BertForTokenClassification.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "qa_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "qa_model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "# Set up pipelines for NER and QA\n",
        "ner_pipe = pipeline('ner', model=ner_model, tokenizer=ner_tokenizer)\n",
        "qa_pipe = pipeline('question-answering', model=qa_model, tokenizer=qa_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Firebase Initialization\n",
        "\n",
        "Initialize Firebase for data storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Firebase initialization\n",
        "cred = credentials.Certificate(\"firebase_config.json\")  # Add your Firebase service account key\n",
        "firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Constants and Data Definitions\n",
        "\n",
        "Define the patterns, document types, and achievements for our application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced legal clauses patterns\n",
        "CLAUSES = {\n",
        "    \"termination\": r\"(termination.*?)(?:\\n|\\.)\",\n",
        "    \"indemnity\": r\"(indemnity.*?)(?:\\n|\\.)\",\n",
        "    \"governing law\": r\"(governing law.*?)(?:\\n|\\.)\",\n",
        "    \"confidentiality\": r\"(confidentiality.*?)(?:\\n|\\.)\",\n",
        "    \"intellectual property\": r\"(intellectual property.*?)(?:\\n|\\.)\",\n",
        "    \"liability\": r\"(liability.*?)(?:\\n|\\.)\",\n",
        "    \"force majeure\": r\"(force majeure.*?)(?:\\n|\\.)\",\n",
        "    \"payment terms\": r\"(payment terms.*?)(?:\\n|\\.)\",\n",
        "    \"arbitration\": r\"(arbitration.*?)(?:\\n|\\.)\",\n",
        "    \"warranties\": r\"(warranties.*?)(?:\\n|\\.)\"\n",
        "}\n",
        "\n",
        "# Define legal document types and their characteristics\n",
        "DOCUMENT_TYPES = {\n",
        "    0: \"Employment Contract\",\n",
        "    1: \"Non-Disclosure Agreement\",\n",
        "    2: \"Service Agreement\",\n",
        "    3: \"Purchase Agreement\",\n",
        "    4: \"License Agreement\",\n",
        "    5: \"Lease Agreement\"\n",
        "}\n",
        "\n",
        "# Achievement definitions\n",
        "ACHIEVEMENTS = {\n",
        "    \"first_scan\": {\"name\": \"Legal Novice\", \"description\": \"Scanned your first document\", \"xp\": 50},\n",
        "    \"scan_milestone_5\": {\"name\": \"Legal Apprentice\", \"description\": \"Scanned 5 documents\", \"xp\": 100},\n",
        "    \"scan_milestone_10\": {\"name\": \"Legal Expert\", \"description\": \"Scanned 10 documents\", \"xp\": 200},\n",
        "    \"quiz_perfect\": {\"name\": \"Perfect Score\", \"description\": \"Got all answers correct in a quiz\", \"xp\": 150},\n",
        "    \"unique_clauses_5\": {\"name\": \"Clause Hunter\", \"description\": \"Discovered 5 different legal clauses\", \"xp\": 125},\n",
        "    \"all_doc_types\": {\"name\": \"Document Master\", \"description\": \"Analyzed all document types\", \"xp\": 300},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Core Functions\n",
        "\n",
        "Now let's define all the core functions for our application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_text_with_bert(text):\n",
        "    \"\"\"Classify text using BERT model\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get the predicted class\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "    return predicted_class % len(DOCUMENT_TYPES)  # Ensure we stay within our defined types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_entities(text):\n",
        "    \"\"\"Extract named entities from text\"\"\"\n",
        "    entities = ner_pipe(text)\n",
        "    named_entities = []\n",
        "    \n",
        "    # Process and group entities\n",
        "    current_entity = \"\"\n",
        "    current_label = \"\"\n",
        "    current_score_sum = 0\n",
        "    count = 0\n",
        "    \n",
        "    for entity in entities:\n",
        "        if entity['word'].startswith('##'):\n",
        "            # Continue previous entity\n",
        "            current_entity += entity['word'][2:]  # Remove the ## prefix\n",
        "            current_score_sum += entity['score']\n",
        "            count += 1\n",
        "        else:\n",
        "            # Save previous entity if it exists\n",
        "            if current_entity and count > 0:\n",
        "                named_entities.append({\n",
        "                    'entity': current_entity,\n",
        "                    'label': current_label,\n",
        "                    'score': current_score_sum / count  # Average score\n",
        "                })\n",
        "            \n",
        "            # Start new entity\n",
        "            current_entity = entity['word']\n",
        "            current_label = entity['entity']\n",
        "            current_score_sum = entity['score']\n",
        "            count = 1\n",
        "    \n",
        "    # Add the last entity\n",
        "    if current_entity and count > 0:\n",
        "        named_entities.append({\n",
        "            'entity': current_entity,\n",
        "            'label': current_label,\n",
        "            'score': current_score_sum / count\n",
        "        })\n",
        "    \n",
        "    # Filter entities with high confidence (score > 0.8)\n",
        "    return [e for e in named_entities if e['score'] > 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def answer_question(context, question):\n",
        "    \"\"\"Get answer to a question from the context\"\"\"\n",
        "    result = qa_pipe(question=question, context=context)\n",
        "    return result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_advanced_quiz(text, clauses):\n",
        "    \"\"\"Generate an enhanced quiz based on document content and extracted clauses\"\"\"\n",
        "    questions = []\n",
        "    \n",
        "    # Question types based on extracted clauses\n",
        "    for key, clause in clauses.items():\n",
        "        # Multiple choice question about the clause\n",
        "        clause_content = clause.split(\":\")[1].strip() if \":\" in clause else clause\n",
        "        \n",
        "        # Generate incorrect options that are plausible but wrong\n",
        "        incorrect_options = [\n",
        "            f\"The {key} clause allows for immediate termination without notice\",\n",
        "            f\"The {key} clause requires written approval from all parties involved\",\n",
        "            f\"The {key} clause limits liability to $10,000 for each occurrence\"\n",
        "        ]\n",
        "        \n",
        "        options = [clause_content] + incorrect_options[:3]  # Use at most 3 incorrect options\n",
        "        random.shuffle(options)\n",
        "        \n",
        "        questions.append({\n",
        "            \"type\": \"multiple_choice\",\n",
        "            \"question\": f\"What does the '{key.title()}' clause specify in this document?\",\n",
        "            \"options\": options,\n",
        "            \"correct_answer\": clause_content,\n",
        "            \"difficulty\": \"medium\",\n",
        "            \"points\": 10\n",
        "        })\n",
        "    \n",
        "    # Generate true/false questions\n",
        "    if len(clauses) > 0:\n",
        "        # Sample some clauses to create true/false questions\n",
        "        sampled_clauses = random.sample(list(clauses.items()), min(2, len(clauses)))\n",
        "        for key, clause in sampled_clauses:\n",
        "            # True statement\n",
        "            questions.append({\n",
        "                \"type\": \"true_false\",\n",
        "                \"question\": f\"This document contains a {key} clause.\",\n",
        "                \"correct_answer\": \"True\",\n",
        "                \"difficulty\": \"easy\",\n",
        "                \"points\": 5\n",
        "            })\n",
        "    \n",
        "    # Generate short answer questions using QA model if we have enough text\n",
        "    if len(text) > 100:\n",
        "        # Create questions based on document content\n",
        "        potential_questions = [\n",
        "            \"Who are the parties involved in this agreement?\",\n",
        "            \"What is the effective date of this document?\",\n",
        "            \"What happens if one party breaches this agreement?\",\n",
        "            \"Is there a notice period specified in the document?\"\n",
        "        ]\n",
        "        \n",
        "        # Sample 2 questions randomly\n",
        "        sampled_questions = random.sample(potential_questions, min(2, len(potential_questions)))\n",
        "        for question in sampled_questions:\n",
        "            try:\n",
        "                answer = answer_question(text, question)\n",
        "                if len(answer) > 2:  # Ensure we got a meaningful answer\n",
        "                    questions.append({\n",
        "                        \"type\": \"short_answer\",\n",
        "                        \"question\": question,\n",
        "                        \"correct_answer\": answer,\n",
        "                        \"difficulty\": \"hard\",\n",
        "                        \"points\": 15\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                # Skip this question if there's an error\n",
        "                print(f\"Error generating question: {e}\")\n",
        "                continue\n",
        "    \n",
        "    # Shuffle the questions\n",
        "    random.shuffle(questions)\n",
        "    \n",
        "    # Limit to 5 questions total\n",
        "    return questions[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_and_award_achievements(user_id):\n",
        "    \"\"\"Check user's progress and award any earned achievements\"\"\"\n",
        "    user_ref = db.collection(\"users\").document(user_id)\n",
        "    user_doc = user_ref.get()\n",
        "    \n",
        "    if not user_doc.exists:\n",
        "        # New user, award first scan achievement\n",
        "        return [ACHIEVEMENTS[\"first_scan\"]]\n",
        "    \n",
        "    user_data = user_doc.to_dict()\n",
        "    earned_achievements = []\n",
        "    \n",
        "    # Get user stats\n",
        "    scan_count = user_data.get(\"scan_count\", 0)\n",
        "    achievements = user_data.get(\"achievements\", [])\n",
        "    unique_clauses = user_data.get(\"unique_clauses\", set())\n",
        "    if isinstance(unique_clauses, list):\n",
        "        unique_clauses = set(unique_clauses)\n",
        "    doc_types = user_data.get(\"doc_types\", set())\n",
        "    if isinstance(doc_types, list):\n",
        "        doc_types = set(doc_types)\n",
        "    \n",
        "    # Check scan milestones\n",
        "    if scan_count == 5 and \"scan_milestone_5\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"scan_milestone_5\"])\n",
        "    \n",
        "    if scan_count == 10 and \"scan_milestone_10\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"scan_milestone_10\"])\n",
        "    \n",
        "    # Check unique clauses\n",
        "    if len(unique_clauses) >= 5 and \"unique_clauses_5\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"unique_clauses_5\"])\n",
        "    \n",
        "    # Check document types\n",
        "    if len(doc_types) == len(DOCUMENT_TYPES) and \"all_doc_types\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"all_doc_types\"])\n",
        "    \n",
        "    return earned_achievements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_to_firebase(text, quiz, clauses, doc_type, user_id=\"anonymous\"):\n",
        "    \"\"\"Save scan data and update user stats in Firebase\"\"\"\n",
        "    # Save the scan\n",
        "    db.collection(\"scans\").add({\n",
        "        \"user_id\": user_id,\n",
        "        \"text\": text,\n",
        "        \"quiz\": quiz,\n",
        "        \"clauses\": list(clauses.keys()),\n",
        "        \"doc_type\": doc_type,\n",
        "        \"xp\": sum(q[\"points\"] for q in quiz),\n",
        "        \"timestamp\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "\n",
        "    # Update user stats\n",
        "    user_ref = db.collection(\"users\").document(user_id)\n",
        "    user_doc = user_ref.get()\n",
        "    \n",
        "    if user_doc.exists:\n",
        "        user_data = user_doc.to_dict()\n",
        "        current_xp = user_data.get(\"xp\", 0)\n",
        "        scan_count = user_data.get(\"scan_count\", 0) + 1\n",
        "        \n",
        "        # Track unique clauses\n",
        "        unique_clauses = set(user_data.get(\"unique_clauses\", []))\n",
        "        unique_clauses.update(clauses.keys())\n",
        "        \n",
        "        # Track document types\n",
        "        doc_types = set(user_data.get(\"doc_types\", []))\n",
        "        doc_types.add(doc_type)\n",
        "        \n",
        "        # Track achievements\n",
        "        achievements = user_data.get(\"achievements\", [])\n",
        "        \n",
        "        user_ref.set({\n",
        "            \"xp\": current_xp + sum(q[\"points\"] for q in quiz),\n",
        "            \"scan_count\": scan_count,\n",
        "            \"unique_clauses\": list(unique_clauses),\n",
        "            \"doc_types\": list(doc_types),\n",
        "            \"achievements\": achievements,\n",
        "            \"updated_at\": datetime.utcnow().isoformat()\n",
        "        }, merge=True)\n",
        "    else:\n",
        "        # Create new user\n",
        "        user_ref.set({\n",
        "            \"user_id\": user_id,\n",
        "            \"xp\": sum(q[\"points\"] for q in quiz),\n",
        "            \"scan_count\": 1,\n",
        "            \"unique_clauses\": list(clauses.keys()),\n",
        "            \"doc_types\": [doc_type],\n",
        "            \"achievements\": [\"first_scan\"],\n",
        "            \"created_at\": datetime.utcnow().isoformat(),\n",
        "            \"updated_at\": datetime.utcnow().isoformat()\n",
        "        })\n",
        "\n",
        "    # Check and award achievements\n",
        "    earned_achievements = check_and_award_achievements(user_id)\n",
        "    \n",
        "    # Update user with earned achievements and XP\n",
        "    if earned_achievements:\n",
        "        achievement_ids = [a[\"name\"] for a in earned_achievements]\n",
        "        achievement_xp = sum(a[\"xp\"] for a in earned_achievements)\n",
        "        \n",
        "        user_doc = user_ref.get().to_dict()\n",
        "        current_xp = user_doc.get(\"xp\", 0)\n",
        "        achievements = user_doc.get(\"achievements\", [])\n",
        "        achievements.extend([a[\"name\"] for a in earned_achievements])\n",
        "        \n",
        "        user_ref.set({\n",
        "            \"xp\": current_xp + achievement_xp,\n",
        "            \"achievements\": list(set(achievements)),  # Remove duplicates\n",
        "        }, merge=True)\n",
        "    \n",
        "    return earned_achievements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flask Routes\n",
        "\n",
        "In a Jupyter environment, we'll define the Flask routes but they won't be active. This is mainly for reference and completeness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template(\"index.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/scan\", methods=[\"POST\"])\n",
        "def scan_document():\n",
        "    file = request.files[\"document\"]\n",
        "    user_id = request.form.get(\"user_id\", \"anonymous\")\n",
        "    \n",
        "    # Read and process the image\n",
        "    image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "\n",
        "    # Classify the extracted text using BERT\n",
        "    classification_result = classify_text_with_bert(text)\n",
        "    doc_type = DOCUMENT_TYPES[classification_result]\n",
        "\n",
        "    # Extract clauses using regex\n",
        "    extracted_clauses = {}\n",
        "    for key, pattern in CLAUSES.items():\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            extracted_clauses[key] = match.group(1)\n",
        "\n",
        "    # Generate enhanced quiz based on extracted clauses\n",
        "    quiz = generate_advanced_quiz(text, extracted_clauses)\n",
        "\n",
        "    # Extract entities using NER\n",
        "    entities = extract_entities(text)\n",
        "\n",
        "    # Answer a sample question using QA model\n",
        "    sample_question = \"What is the main purpose of this document?\"\n",
        "    answer = answer_question(text, sample_question)\n",
        "\n",
        "    # Save the scan and quiz data to Firebase and get earned achievements\n",
        "    earned_achievements = save_to_firebase(text, quiz, extracted_clauses, doc_type, user_id)\n",
        "\n",
        "    return render_template(\n",
        "        \"results.html\", \n",
        "        doc_type=doc_type,\n",
        "        clauses=extracted_clauses, \n",
        "        quiz=quiz, \n",
        "        classification=classification_result, \n",
        "        entities=entities, \n",
        "        answer=answer,\n",
        "        achievements=earned_achievements\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df32b0cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/analyze_document\", methods=[\"POST\"])\n",
        "def analyze_document():\n",
        "    file = request.files[\"document\"]\n",
        "    user_id = request.form.get(\"user_id\", \"anonymous\")\n",
        "    \n",
        "    # Process the file - both image and text documents\n",
        "    if file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
        "        # Process image file with OCR\n",
        "        image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "        text = pytesseract.image_to_string(image)\n",
        "    else:\n",
        "        # Handle text-based documents (PDFs would need additional processing)\n",
        "        text = file.read().decode('utf-8', errors='ignore')\n",
        "    \n",
        "    # Always use auto-detection for document type\n",
        "    classification_result = classify_text_with_bert(text)\n",
        "    doc_type = DOCUMENT_TYPES[classification_result]\n",
        "\n",
        "    # Extract clauses using regex\n",
        "    extracted_clauses = {}\n",
        "    for key, pattern in CLAUSES.items():\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            extracted_clauses[key] = match.group(1)\n",
        "\n",
        "    # Generate enhanced quiz based on extracted clauses\n",
        "    quiz = generate_advanced_quiz(text, extracted_clauses)\n",
        "\n",
        "    # Extract entities using NER\n",
        "    entities = extract_entities(text)\n",
        "\n",
        "    # Save the scan and quiz data to Firebase and get earned achievements\n",
        "    earned_achievements = save_to_firebase(text, quiz, extracted_clauses, doc_type, user_id)\n",
        "\n",
        "    # Get recent scans for this user to display\n",
        "    recent_scans = db.collection(\"scans\").where(\"user_id\", \"==\", user_id).order_by(\n",
        "        \"timestamp\", direction=firestore.Query.DESCENDING\n",
        "    ).limit(5).stream()\n",
        "    \n",
        "    recent_scan_data = []\n",
        "    for scan in recent_scans:\n",
        "        scan_data = scan.to_dict()\n",
        "        scan_data[\"id\"] = scan.id\n",
        "        recent_scan_data.append(scan_data)\n",
        "\n",
        "    return render_template(\n",
        "        \"results.html\", \n",
        "        doc_type=doc_type,\n",
        "        clauses=extracted_clauses, \n",
        "        quiz=quiz,\n",
        "        entities=entities,\n",
        "        user_id=user_id,\n",
        "        recent_scans=recent_scan_data,\n",
        "        achievements=earned_achievements\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890d6e13",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/submit_quiz\", methods=[\"POST\"])\n",
        "def submit_quiz():\n",
        "    scan_id = request.args.get(\"scan_id\", \"\")\n",
        "    user_id = request.args.get(\"user\", \"anonymous\")\n",
        "    \n",
        "    # Get the quiz questions from Firebase\n",
        "    scan_doc = db.collection(\"scans\").document(scan_id).get()\n",
        "    if not scan_doc.exists:\n",
        "        flash(\"Quiz not found.\")\n",
        "        return redirect(url_for(\"index\"))\n",
        "    \n",
        "    scan_data = scan_doc.to_dict()\n",
        "    quiz = scan_data.get(\"quiz\", [])\n",
        "    \n",
        "    # Score the quiz\n",
        "    score = 0\n",
        "    total_possible = sum(q[\"points\"] for q in quiz)\n",
        "    answers = []\n",
        "    \n",
        "    for i, question in enumerate(quiz):\n",
        "        user_answer = request.form.get(f\"q{i}\", \"\")\n",
        "        correct = False\n",
        "        \n",
        "        if user_answer == question[\"correct_answer\"]:\n",
        "            score += question[\"points\"]\n",
        "            correct = True\n",
        "        \n",
        "        answers.append({\n",
        "            \"question\": question[\"question\"],\n",
        "            \"user_answer\": user_answer,\n",
        "            \"correct_answer\": question[\"correct_answer\"],\n",
        "            \"correct\": correct,\n",
        "            \"points\": question[\"points\"] if correct else 0\n",
        "        })\n",
        "    \n",
        "    # Check for perfect score achievement\n",
        "    if score == total_possible:\n",
        "        # Update user with perfect score achievement\n",
        "        user_ref = db.collection(\"users\").document(user_id)\n",
        "        user_doc = user_ref.get()\n",
        "        \n",
        "        if user_doc.exists:\n",
        "            user_data = user_doc.to_dict()\n",
        "            achievements = user_data.get(\"achievements\", [])\n",
        "            \n",
        "            if \"quiz_perfect\" not in achievements:\n",
        "                achievements.append(\"quiz_perfect\")\n",
        "                current_xp = user_data.get(\"xp\", 0)\n",
        "                \n",
        "                user_ref.update({\n",
        "                    \"achievements\": achievements,\n",
        "                    \"xp\": current_xp + ACHIEVEMENTS[\"quiz_perfect\"][\"xp\"]\n",
        "                })\n",
        "    \n",
        "    # Save quiz results\n",
        "    db.collection(\"quiz_results\").add({\n",
        "        \"user_id\": user_id,\n",
        "        \"scan_id\": scan_id,\n",
        "        \"score\": score,\n",
        "        \"total_possible\": total_possible,\n",
        "        \"answers\": answers,\n",
        "        \"timestamp\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "    \n",
        "    return render_template(\n",
        "        \"quiz_results.html\",\n",
        "        score=score,\n",
        "        total_possible=total_possible,\n",
        "        answers=answers,\n",
        "        perfect_score=(score == total_possible)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876f0351",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/leaderboard\")\n",
        "def leaderboard():\n",
        "    # Get top users by XP\n",
        "    users_ref = db.collection(\"users\").order_by(\"xp\", direction=firestore.Query.DESCENDING).limit(10)\n",
        "    users = []\n",
        "    \n",
        "    for doc in users_ref.stream():\n",
        "        user_data = doc.to_dict()\n",
        "        user_id = user_data.get(\"user_id\", doc.id)\n",
        "        xp = user_data.get(\"xp\", 0)\n",
        "        level = xp // 100\n",
        "        scan_count = user_data.get(\"scan_count\", 0)\n",
        "        achievement_count = len(user_data.get(\"achievements\", []))\n",
        "        \n",
        "        users.append({\n",
        "            \"user_id\": user_id,\n",
        "            \"xp\": xp,\n",
        "            \"level\": level,\n",
        "            \"scan_count\": scan_count,\n",
        "            \"achievement_count\": achievement_count\n",
        "        })\n",
        "    \n",
        "    # Get current user's rank if provided\n",
        "    current_user = request.args.get(\"user\")\n",
        "    current_user_rank = None\n",
        "    \n",
        "    if current_user:\n",
        "        # Get all users\n",
        "        all_users = list(db.collection(\"users\").order_by(\"xp\", direction=firestore.Query.DESCENDING).stream())\n",
        "        \n",
        "        # Find current user's position\n",
        "        for i, user_doc in enumerate(all_users):\n",
        "            if user_doc.id == current_user or user_doc.to_dict().get(\"user_id\") == current_user:\n",
        "                current_user_rank = i + 1\n",
        "                break\n",
        "    \n",
        "    return render_template(\n",
        "        \"leaderboard.html\",\n",
        "        users=users,\n",
        "        current_user=current_user,\n",
        "        current_user_rank=current_user_rank\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22b4a40",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route('/take_quiz')\n",
        "def take_quiz():\n",
        "    scan_id = request.args.get('scan_id', '')\n",
        "    user_id = request.args.get('user', '')\n",
        "    \n",
        "    # Fetch the quiz data based on scan_id\n",
        "    # This is a placeholder - replace with your actual database query\n",
        "    try:\n",
        "        # Example: Fetch from Firestore\n",
        "        doc_ref = db.collection('scans').document(scan_id)\n",
        "        scan_doc = doc_ref.get()\n",
        "        \n",
        "        if scan_doc.exists:\n",
        "            scan_data = scan_doc.to_dict()\n",
        "            quiz_data = scan_data.get('quiz', [])\n",
        "        else:\n",
        "            # Handle case where scan doesn't exist\n",
        "            flash(\"Scan not found\", \"error\")\n",
        "            return redirect(url_for('index'))\n",
        "            \n",
        "    except Exception as e:\n",
        "        # Handle any errors\n",
        "        flash(f\"Error retrieving quiz: {str(e)}\", \"error\")\n",
        "        return redirect(url_for('index'))\n",
        "    \n",
        "    # Render the quiz template with the retrieved data\n",
        "    return render_template('qiuz.html', scan_id=scan_id, user_id=user_id, quiz=quiz_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e7b4f4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/dashboard\")\n",
        "def dashboard():\n",
        "    user_id = request.args.get(\"user\", \"anonymous\")\n",
        "    user_ref = db.collection(\"users\").document(user_id)\n",
        "    user_data = user_ref.get().to_dict()\n",
        "\n",
        "    xp = user_data[\"xp\"] if user_data else 0\n",
        "    level = xp // 100\n",
        "    progress = xp % 100\n",
        "\n",
        "    return render_template(\"dashboard.html\", xp=xp, level=level, progress=progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adc8e0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import threading to run Flask in a separate thread\n",
        "import threading\n",
        "\n",
        "def run_flask():\n",
        "    app.run(debug=False, use_reloader=False)  # Disable reloader and debug for notebook use\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "flask_thread = threading.Thread(target=run_flask)\n",
        "flask_thread.daemon = True  # This makes the thread exit when the notebook is closed\n",
        "flask_thread.start()\n",
        "\n",
        "print(\"Flask server is running in the background. Access it at http://127.0.0.1:5000\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
