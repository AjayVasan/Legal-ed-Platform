{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "47ac90cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\legal-ed-platform\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, redirect, url_for, flash\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline, BertForTokenClassification, BertForQuestionAnswering\n",
        "from datetime import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "91bbd7fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up Tesseract path\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
        "app = Flask(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b9b377ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "ak = open(\"HF.txt\",\"r\")\n",
        "hf_ak = ak.readline()\n",
        "# print(hf_ak)\n",
        "# print(type(hf_ak))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5c2940e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question 1: [question text]\n",
            " ✓ A) [option 1]\n",
            "   B) [option 4]\n",
            "   C) [option 2]\n",
            "   D) [option 3]\n",
            "\n",
            "Question 2: How long does the confidentiality clause require parties to keep information secret for after contract termination?\n",
            "   A) Until the parties mutually agree (A)\n",
            "   B) Lifetime (D)\n",
            " ✓ C) 3 years\n",
            "   D) 1 year (B)\n",
            "\n",
            "Question 3: According to the termination clause, how much notice is required for either party to terminate the contract?\n",
            "   A) 180 days (D)\n",
            " ✓ B) 60 days\n",
            "   C) 364 days (A)\n",
            "   D) 90 days (B)\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import random\n",
        "from time import sleep\n",
        "from functools import lru_cache\n",
        "import json\n",
        "\n",
        "# HuggingFace Setup - REPLACE WITH YOUR ACTUAL TOKEN\n",
        "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "HF_TOKEN = hf_ak  # Get from https://huggingface.co/settings/tokens\n",
        "headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
        "\n",
        "@lru_cache(maxsize=100)\n",
        "def generate_hf_questions(text, clauses_str, num_questions=3, max_retries=3):\n",
        "    \"\"\"Generate quiz questions using HuggingFace API with randomized answer positions\"\"\"\n",
        "    # Convert clauses string back to dict for use in the function\n",
        "    clauses = json.loads(clauses_str)\n",
        "    \n",
        "    prompt = f\"\"\"Generate {num_questions} multiple-choice legal quiz questions from this contract with these requirements:\n",
        "    \n",
        "1. For each question:\n",
        "   - Provide one correct answer (marked with (CORRECT))\n",
        "   - Provide three plausible but incorrect answers\n",
        "2. Format each question exactly like:\n",
        "   Q: [question text]\n",
        "   A: [option 1] (CORRECT)\n",
        "   B: [option 2]\n",
        "   C: [option 3]\n",
        "   D: [option 4]\n",
        "   \n",
        "Document Excerpt:\n",
        "{text[:1000]}\n",
        "\n",
        "Key Clauses:\n",
        "{clauses_str}\n",
        "\"\"\"\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                API_URL,\n",
        "                headers=headers,\n",
        "                json={\n",
        "                    \"inputs\": prompt,\n",
        "                    \"parameters\": {\n",
        "                        \"max_length\": 800,\n",
        "                        \"temperature\": 0.7,\n",
        "                        \"do_sample\": True\n",
        "                    }\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                generated_text = response.json()[0]['generated_text']\n",
        "                questions = parse_hf_response(generated_text)\n",
        "                if questions:  # Only return if we got valid questions\n",
        "                    return questions\n",
        "                \n",
        "            elif response.status_code == 503:  # Model loading\n",
        "                print(f\"Model loading, retrying... (attempt {attempt + 1})\")\n",
        "                sleep(5)  # Wait before retrying\n",
        "                continue\n",
        "                \n",
        "            else:\n",
        "                print(f\"HF API Error: {response.text}\")\n",
        "                return []\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"HF Request Failed: {str(e)}\")\n",
        "            return []\n",
        "    \n",
        "    return []  # Return empty if all retries failed\n",
        "\n",
        "def parse_hf_response(text):\n",
        "    \"\"\"Parse the generated text into quiz format with randomized answer positions\"\"\"\n",
        "    questions = []\n",
        "    current_question = None\n",
        "    \n",
        "    for line in text.split('\\n'):\n",
        "        line = line.strip()\n",
        "        \n",
        "        # New question detected\n",
        "        if line.startswith('Q:'):\n",
        "            if current_question:  # Save previous question if exists\n",
        "                questions.append(current_question)\n",
        "                \n",
        "            current_question = {\n",
        "                \"question\": line[2:].strip(),\n",
        "                \"options\": [],\n",
        "                \"correct_answer\": \"\",\n",
        "                \"type\": \"multiple_choice\"\n",
        "            }\n",
        "        \n",
        "        # Answer option detected\n",
        "        elif line and line[0] in 'ABCD' and current_question:\n",
        "            option_text = line[3:].strip()\n",
        "            \n",
        "            # Check if this is the correct answer\n",
        "            if \"(CORRECT)\" in option_text:\n",
        "                clean_option = option_text.replace(\"(CORRECT)\", \"\").strip()\n",
        "                current_question[\"correct_answer\"] = clean_option\n",
        "                current_question[\"options\"].append(clean_option)\n",
        "            else:\n",
        "                current_question[\"options\"].append(option_text)\n",
        "    \n",
        "    # Add the last question if exists\n",
        "    if current_question and current_question[\"options\"]:\n",
        "        questions.append(current_question)\n",
        "    \n",
        "    # Randomize option order for each question\n",
        "    for question in questions:\n",
        "        if len(question[\"options\"]) >= 4:\n",
        "            # Get all options except correct answer\n",
        "            other_options = [opt for opt in question[\"options\"] if opt != question[\"correct_answer\"]]\n",
        "            other_options = other_options[:3]  # Ensure we only have 3 incorrect options\n",
        "            \n",
        "            # Combine and shuffle\n",
        "            all_options = [question[\"correct_answer\"]] + other_options\n",
        "            random.shuffle(all_options)\n",
        "            \n",
        "            # Update question with randomized options\n",
        "            question[\"options\"] = all_options\n",
        "    \n",
        "    return questions\n",
        "\n",
        "# Fallback question generator\n",
        "def generate_fallback_questions(text, clauses, num_questions=3):\n",
        "    \"\"\"Generate simple questions if HF API fails\"\"\"\n",
        "    questions = []\n",
        "    clause_items = list(clauses.items())\n",
        "    \n",
        "    for i in range(min(num_questions, len(clause_items))):\n",
        "        key, clause = clause_items[i]\n",
        "        clause_content = clause.split(\":\")[1].strip() if \":\" in clause else clause\n",
        "        \n",
        "        questions.append({\n",
        "            \"question\": f\"What does the '{key}' clause specify?\",\n",
        "            \"options\": [\n",
        "                clause_content,\n",
        "                f\"The {key} clause is not specified\",\n",
        "                f\"The {key} clause allows unlimited disclosure\",\n",
        "                f\"The {key} clause has no time limit\"\n",
        "            ],\n",
        "            \"correct_answer\": clause_content,\n",
        "            \"type\": \"multiple_choice\"\n",
        "        })\n",
        "        \n",
        "        # Shuffle options\n",
        "        random.shuffle(questions[-1][\"options\"])\n",
        "    \n",
        "    return questions\n",
        "\n",
        "# Main function to use in your application\n",
        "def generate_quiz_questions(text, clauses, num_questions=3):\n",
        "    \"\"\"Main function to generate questions, with fallback\"\"\"\n",
        "    # Convert clauses to string for caching\n",
        "    clauses_str = json.dumps(clauses, sort_keys=True)\n",
        "    questions = generate_hf_questions(text, clauses_str, num_questions)\n",
        "    \n",
        "    if not questions:  # If HF API failed\n",
        "        print(\"Using fallback question generator\")\n",
        "        questions = generate_fallback_questions(text, clauses, num_questions)\n",
        "    \n",
        "    return questions[:num_questions]  # Ensure we don't return more than requested\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    sample_text = \"\"\"The confidentiality clause requires parties to keep information secret for 2 years after contract termination. \n",
        "    The termination clause allows either party to terminate with 30 days notice.\"\"\"\n",
        "    \n",
        "    sample_clauses = {\n",
        "        \"confidentiality\": \"Parties must keep confidential information secret for 2 years post-termination\",\n",
        "        \"termination\": \"Either party may terminate with 30 days notice\"\n",
        "    }\n",
        "    \n",
        "    questions = generate_quiz_questions(sample_text, sample_clauses)\n",
        "    \n",
        "    for i, q in enumerate(questions, 1):\n",
        "        print(f\"\\nQuestion {i}: {q['question']}\")\n",
        "        for j, opt in enumerate(q['options']):\n",
        "            prefix = \"✓\" if opt == q['correct_answer'] else \" \"\n",
        "            print(f\" {prefix} {'ABCD'[j]}) {opt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fcadb8fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Initialize models\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "ner_tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "ner_model = BertForTokenClassification.from_pretrained('dbmdz/bert-large-cased-finetuned-conll03-english')\n",
        "qa_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "qa_model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b508b4ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Initialize pipelines\n",
        "ner_pipe = pipeline('ner', model=ner_model, tokenizer=ner_tokenizer)\n",
        "qa_pipe = pipeline('question-answering', model=qa_model, tokenizer=qa_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cc0bdd67",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Firebase initialized successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize Firebase with proper check\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(\"firebase_config.json\")  # Replace with your credentials path\n",
        "        firebase_admin.initialize_app(cred)\n",
        "        db = firestore.client()\n",
        "        print(\"Firebase initialized successfully\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: firebase_config.json not found. Please ensure the file exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Firebase: {str(e)}\")\n",
        "else:\n",
        "    db = firestore.client()  # Get the client if app already exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "980a0aa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define constants\n",
        "# Update CLAUSES to better handle license agreement sections\n",
        "CLAUSES = {\n",
        "    \"permitted uses\": r\"(Permitted Uses\\..*?)(?=\\\\n\\\\s*\\\\n|$)\",\n",
        "    \"use restrictions\": r\"(Use Restrictions\\..*?)(?=\\\\n\\\\s*\\\\n|$)\",\n",
        "    \"data usage\": r\"(Customer may (?:not )?use Data.*?)(?=\\\\n|$)\",\n",
        "    \"geocoding\": r\"(geocod.*?)(?=\\\\n|$)\",\n",
        "    \"redistribution\": r\"(redistribut.*?)(?=\\\\n|$)\",\n",
        "    # Keep your existing clauses too\n",
        "    \"termination\": r\"(termination.*?)(?:\\\\n|\\\\.)\",\n",
        "    \"confidentiality\": r\"(confidentiality.*?)(?:\\\\n|\\\\.)\",\n",
        "    # ... other existing clauses\n",
        "}\n",
        "\n",
        "def extract_clauses(text):\n",
        "    \"\"\"Enhanced clause extraction with section headers\"\"\"\n",
        "    clauses = {}\n",
        "    \n",
        "    # First extract section headers\n",
        "    for key, pattern in CLAUSES.items():\n",
        "        matches = re.finditer(pattern, text, re.IGNORECASE | re.DOTALL)\n",
        "        for match in matches:\n",
        "            clause_text = match.group(1).strip()\n",
        "            if len(clause_text) > 20:  # Minimum length threshold\n",
        "                clauses[f\"{key}\"] = clause_text\n",
        "    \n",
        "    # Additional pattern for numbered clauses\n",
        "    numbered_clauses = re.finditer(r\"(\\\\d+\\\\.\\\\s+[a-z]?\\\\..*?)(?=\\\\n\\\\s*\\\\d+\\\\.|$)\", text, re.DOTALL)\n",
        "    for i, match in enumerate(numbered_clauses, 1):\n",
        "        clauses[f\"clause_{i}\"] = match.group(1).strip()\n",
        "    \n",
        "    return clauses\n",
        "\n",
        "# Update DOCUMENT_TYPES to better handle license agreements\n",
        "DOCUMENT_TYPES = {\n",
        "    0: \"Employment Contract\",\n",
        "    1: \"Non-Disclosure Agreement\",\n",
        "    2: \"Service Agreement\",\n",
        "    3: \"Purchase Agreement\",\n",
        "    4: \"License Agreement\",  # This should match your document\n",
        "    5: \"Lease Agreement\"\n",
        "}\n",
        "\n",
        "def classify_text_with_bert(text):\n",
        "    \"\"\"Enhanced classification with keyword fallback\"\"\"\n",
        "    # First try BERT\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item() % len(DOCUMENT_TYPES)\n",
        "    \n",
        "    # Keyword fallback for license agreements\n",
        "    text_lower = text.lower()\n",
        "    if \"permitted uses\" in text_lower or \"use restrictions\" in text_lower:\n",
        "        return 4  # License Agreement\n",
        "    if \"confidential\" in text_lower:\n",
        "        return 1  # NDA\n",
        "    \n",
        "    return predicted_class\n",
        "\n",
        "ACHIEVEMENTS = {\n",
        "    \"first_scan\": {\"name\": \"Legal Novice\", \"description\": \"Scanned your first document\", \"xp\": 50},\n",
        "    \"scan_milestone_5\": {\"name\": \"Legal Apprentice\", \"description\": \"Scanned 5 documents\", \"xp\": 100},\n",
        "    \"scan_milestone_10\": {\"name\": \"Legal Expert\", \"description\": \"Scanned 10 documents\", \"xp\": 200},\n",
        "    \"quiz_perfect\": {\"name\": \"Perfect Score\", \"description\": \"Got all answers correct in a quiz\", \"xp\": 150},\n",
        "    \"unique_clauses_5\": {\"name\": \"Clause Hunter\", \"description\": \"Discovered 5 different legal clauses\", \"xp\": 125},\n",
        "    \"all_doc_types\": {\"name\": \"Document Master\", \"description\": \"Analyzed all document types\", \"xp\": 300}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b328d1b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_license_quiz(text, clauses):\n",
        "    \"\"\"Specialized quiz generator for license agreements\"\"\"\n",
        "    questions = []\n",
        "    \n",
        "    # Question about permitted uses\n",
        "    if \"permitted uses\" in clauses:\n",
        "        questions.append({\n",
        "            \"question\": \"What are the permitted uses of the data according to this agreement?\",\n",
        "            \"options\": [\n",
        "                clauses[\"permitted uses\"],\n",
        "                \"Unlimited use for any purpose\",\n",
        "                \"Only for personal non-commercial use\",\n",
        "                \"Only for government projects\"\n",
        "            ],\n",
        "            \"correct_answer\": clauses[\"permitted uses\"],\n",
        "            \"type\": \"multiple_choice\",\n",
        "            \"points\": 15\n",
        "        })\n",
        "    \n",
        "    # Question about restrictions\n",
        "    if \"use restrictions\" in clauses:\n",
        "        questions.append({\n",
        "            \"question\": \"Which of these is NOT a restriction mentioned in the agreement?\",\n",
        "            \"options\": [\n",
        "                \"Using data for academic research\",\n",
        "                \"Using data for real-time navigation\",\n",
        "                \"Redistributing business listing data\",\n",
        "                \"Caching data without authorization\"\n",
        "            ],\n",
        "            \"correct_answer\": \"Using data for academic research\",\n",
        "            \"type\": \"multiple_choice\",\n",
        "            \"points\": 15\n",
        "        })\n",
        "    \n",
        "    # Add more specialized questions as needed\n",
        "    return questions[:5]  # Return max 5 questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2ff45071",
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_text_with_bert(text):\n",
        "    \"\"\"Classify text using BERT model\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "    return predicted_class % len(DOCUMENT_TYPES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5a12b777",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_entities(text):\n",
        "    \"\"\"Extract named entities from text\"\"\"\n",
        "    entities = ner_pipe(text)\n",
        "    named_entities = []\n",
        "    current_entity = \"\"\n",
        "    current_label = \"\"\n",
        "    current_score_sum = 0\n",
        "    count = 0\n",
        "\n",
        "    for entity in entities:\n",
        "        if entity['entity'].startswith('B-') or entity['entity'].startswith('I-'):\n",
        "            current_score_sum += entity['score']\n",
        "            count += 1\n",
        "        else:\n",
        "            if current_entity and count > 0:\n",
        "                named_entities.append({\n",
        "                    'entity': current_entity,\n",
        "                    'label': current_label,\n",
        "                    'score': current_score_sum / count\n",
        "                })\n",
        "        \n",
        "            current_entity = entity['word']\n",
        "            current_label = entity['entity']\n",
        "            current_score_sum = entity['score']\n",
        "            count = 1\n",
        "\n",
        "    if current_entity and count > 0:\n",
        "        named_entities.append({\n",
        "            'entity': current_entity,\n",
        "            'label': current_label,\n",
        "            'score': current_score_sum / count\n",
        "        })\n",
        "\n",
        "    return [e for e in named_entities if e['score'] > 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "87470245",
      "metadata": {},
      "outputs": [],
      "source": [
        "def answer_question(context, question):\n",
        "    \"\"\"Get answer to a question from the context\"\"\"\n",
        "    result = qa_pipe(question=question, context=context)\n",
        "    return result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "63d5485a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_advanced_quiz(text, clauses):\n",
        "    \"\"\"Generate an enhanced quiz based on document content and extracted clauses\"\"\"\n",
        "    questions = []\n",
        "\n",
        "    for key, clause in clauses.items():\n",
        "        clause_content = clause.split(\":\")[1].strip() if \":\" in clause else clause\n",
        "    \n",
        "        incorrect_options = [\n",
        "            f\"The {key} clause allows for immediate termination without notice\",\n",
        "            f\"The {key} clause requires written approval from all parties involved\",\n",
        "            f\"The {key} clause limits liability to $10,000 for each occurrence\"\n",
        "        ]\n",
        "        \n",
        "        options = [clause_content] + incorrect_options[:3]\n",
        "        random.shuffle(options)\n",
        "    \n",
        "        questions.append({\n",
        "            \"type\": \"multiple_choice\",\n",
        "            \"question\": f\"What does the '{key.title()}' clause specify in this document?\",\n",
        "            \"options\": options,\n",
        "            \"correct_answer\": clause_content,\n",
        "            \"difficulty\": \"medium\",\n",
        "            \"points\": 10\n",
        "        })\n",
        "\n",
        "    if len(clauses) > 0:\n",
        "        sampled_clauses = random.sample(list(clauses.items()), min(2, len(clauses)))\n",
        "        for key, clause in sampled_clauses:\n",
        "            questions.append({\n",
        "                \"type\": \"true_false\",\n",
        "                \"question\": f\"This document contains a {key} clause.\",\n",
        "                \"correct_answer\": \"True\",\n",
        "                \"difficulty\": \"easy\",\n",
        "                \"points\": 5\n",
        "            })\n",
        "\n",
        "    if len(text) > 100:\n",
        "        potential_questions = [\n",
        "            \"Who are the parties involved in this agreement?\",\n",
        "            \"What is the effective date of this document?\",\n",
        "            \"What happens if one party breaches this agreement?\",\n",
        "            \"Is there a notice period specified in the document?\"\n",
        "        ]\n",
        "    \n",
        "        sampled_questions = random.sample(potential_questions, min(2, len(potential_questions)))\n",
        "        for question in sampled_questions:\n",
        "            try:\n",
        "                answer = answer_question(text, question)\n",
        "                if len(answer) > 2: \n",
        "                    questions.append({\n",
        "                        \"type\": \"short_answer\",\n",
        "                        \"question\": question,\n",
        "                        \"correct_answer\": answer,\n",
        "                        \"difficulty\": \"hard\",\n",
        "                        \"points\": 15\n",
        "                    })\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating question: {e}\")\n",
        "                continue\n",
        "\n",
        "    random.shuffle(questions)\n",
        "\n",
        "    return questions[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f6d8f82d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_and_award_achievements(user_id):\n",
        "    \"\"\"Check user's progress and award any earned achievements\"\"\"\n",
        "    user_ref = db.collection(\"users\").document(user_id)\n",
        "    user_doc = user_ref.get()\n",
        "\n",
        "    if not user_doc.exists:\n",
        "        return [ACHIEVEMENTS[\"first_scan\"]]\n",
        "\n",
        "    user_data = user_doc.to_dict()\n",
        "    earned_achievements = []\n",
        "\n",
        "    scan_count = user_data.get(\"scan_count\", 0)\n",
        "    achievements = user_data.get(\"achievements\", [])\n",
        "    unique_clauses = user_data.get(\"unique_clauses\", set())\n",
        "    if isinstance(unique_clauses, list):\n",
        "        unique_clauses = set(unique_clauses)\n",
        "    doc_types = user_data.get(\"doc_types\", set())\n",
        "    if isinstance(doc_types, list):\n",
        "        doc_types = set(doc_types)\n",
        "\n",
        "    if scan_count == 5 and \"scan_milestone_5\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"scan_milestone_5\"])\n",
        "\n",
        "    if scan_count == 10 and \"scan_milestone_10\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"scan_milestone_10\"])\n",
        "\n",
        "    if len(unique_clauses) >= 5 and \"unique_clauses_5\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"unique_clauses_5\"])\n",
        "\n",
        "    if len(doc_types) == len(DOCUMENT_TYPES) and \"all_doc_types\" not in achievements:\n",
        "        earned_achievements.append(ACHIEVEMENTS[\"all_doc_types\"])\n",
        "\n",
        "    return earned_achievements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b7e119aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_to_firebase(text, quiz, clauses, doc_type, user_id=\"anonymous\"):\n",
        "    \"\"\"Save scan data and update user stats in Firebase\"\"\"\n",
        "    db.collection(\"scans\").add({\n",
        "        \"user_id\": user_id,\n",
        "        \"text\": text,\n",
        "        \"quiz\": quiz,\n",
        "        \"clauses\": list(clauses.keys()),\n",
        "        \"doc_type\": doc_type,\n",
        "        \"xp\": sum(q[\"points\"] for q in quiz),\n",
        "        \"timestamp\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "    \n",
        "    user_ref = db.collection(\"users\").document(user_id)\n",
        "    user_doc = user_ref.get()\n",
        "\n",
        "    if user_doc.exists:\n",
        "        user_data = user_doc.to_dict()\n",
        "        current_xp = user_data.get(\"xp\", 0)\n",
        "        scan_count = user_data.get(\"scan_count\", 0) + 1\n",
        "    \n",
        "        unique_clauses = set(user_data.get(\"unique_clauses\", []))\n",
        "        unique_clauses.update(clauses.keys())\n",
        "    \n",
        "        doc_types = set(user_data.get(\"doc_types\", []))\n",
        "        doc_types.add(doc_type)\n",
        "    \n",
        "        achievements = user_data.get(\"achievements\", [])\n",
        "    \n",
        "        user_ref.set({\n",
        "            \"xp\": current_xp + sum(q[\"points\"] for q in quiz),\n",
        "            \"scan_count\": scan_count,\n",
        "            \"unique_clauses\": list(unique_clauses),\n",
        "            \"doc_types\": list(doc_types),\n",
        "            \"achievements\": achievements,\n",
        "            \"updated_at\": datetime.utcnow().isoformat()\n",
        "        }, merge=True)\n",
        "    else:\n",
        "        user_ref.set({\n",
        "            \"user_id\": user_id,\n",
        "            \"xp\": sum(q[\"points\"] for q in quiz),\n",
        "            \"scan_count\": 1,\n",
        "            \"unique_clauses\": list(clauses.keys()),\n",
        "            \"doc_types\": [doc_type],\n",
        "            \"achievements\": [\"first_scan\"],\n",
        "            \"created_at\": datetime.utcnow().isoformat(),\n",
        "            \"updated_at\": datetime.utcnow().isoformat()\n",
        "        })\n",
        "        \n",
        "    earned_achievements = check_and_award_achievements(user_id)\n",
        "\n",
        "    if earned_achievements:\n",
        "        achievement_ids = [a[\"name\"] for a in earned_achievements]\n",
        "        achievement_xp = sum(a[\"xp\"] for a in earned_achievements)\n",
        "    \n",
        "        user_doc = user_ref.get().to_dict()\n",
        "        current_xp = user_doc.get(\"xp\", 0)\n",
        "        achievements = user_doc.get(\"achievements\", [])\n",
        "        achievements.extend([a[\"name\"] for a in earned_achievements])\n",
        "    \n",
        "        user_ref.set({\n",
        "            \"xp\": current_xp + achievement_xp,\n",
        "            \"achievements\": achievements\n",
        "        }, merge=True)\n",
        "\n",
        "    return earned_achievements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4cdef33d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_advanced_quiz(text, clauses):\n",
        "    \"\"\"Generate a multiple-choice quiz based on document content and extracted clauses\"\"\"\n",
        "    questions = []\n",
        "\n",
        "    for key, clause in clauses.items():\n",
        "        clause_content = clause.split(\":\")[1].strip() if \":\" in clause else clause\n",
        "    \n",
        "        incorrect_options = [\n",
        "            f\"The {key} clause allows for immediate termination without notice\",\n",
        "            f\"The {key} clause requires written approval from all parties involved\",\n",
        "            f\"The {key} clause limits liability to $10,000 for each occurrence\"\n",
        "        ]\n",
        "        \n",
        "        options = [clause_content] + incorrect_options[:3]\n",
        "        random.shuffle(options)\n",
        "    \n",
        "        questions.append({\n",
        "            \"type\": \"multiple_choice\",\n",
        "            \"question\": f\"What does the '{key.title()}' clause specify in this document?\",\n",
        "            \"options\": options,\n",
        "            \"correct_answer\": clause_content\n",
        "        })\n",
        "\n",
        "    if len(clauses) > 0:\n",
        "        sampled_clauses = random.sample(list(clauses.items()), min(2, len(clauses)))\n",
        "        for key, clause in sampled_clauses:\n",
        "            questions.append({\n",
        "                \"type\": \"true_false\",\n",
        "                \"question\": f\"This document contains a {key} clause.\",\n",
        "                \"correct_answer\": \"True\"\n",
        "            })\n",
        "\n",
        "    random.shuffle(questions)\n",
        "    return questions[:5]  # Return max 5 questions\n",
        "\n",
        "\n",
        "def save_to_firebase(text, quiz, clauses, doc_type, user_id=\"anonymous\"):\n",
        "    \"\"\"Save scan data and update user stats in Firebase\"\"\"\n",
        "    db.collection(\"scans\").add({\n",
        "        \"user_id\": user_id,\n",
        "        \"text\": text,\n",
        "        \"quiz\": quiz,\n",
        "        \"clauses\": list(clauses.keys()),\n",
        "        \"doc_type\": doc_type,\n",
        "        \"timestamp\": datetime.utcnow().isoformat()\n",
        "    })\n",
        "    \n",
        "    # Rest of the function remains the same, just remove any XP calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "222f78b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template(\"index.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7b4820e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/scan\", methods=[\"POST\"])\n",
        "def scan_document():\n",
        "    file = request.files[\"document\"]\n",
        "    user_id = request.form.get(\"user_id\", \"anonymous\")\n",
        "\n",
        "    image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    classification_result = classify_text_with_bert(text)\n",
        "    doc_type = DOCUMENT_TYPES[classification_result]\n",
        "    \n",
        "    extracted_clauses = {}\n",
        "    for key, pattern in CLAUSES.items():\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            extracted_clauses[key] = match.group(1)\n",
        "            \n",
        "    quiz = generate_advanced_quiz(text, extracted_clauses)\n",
        "    entities = extract_entities(text)\n",
        "    sample_question = \"What is the main purpose of this document?\"\n",
        "    answer = answer_question(text, sample_question)\n",
        "    \n",
        "    earned_achievements = save_to_firebase(text, quiz, extracted_clauses, doc_type, user_id)\n",
        "    \n",
        "    return render_template(\n",
        "        \"results.html\",\n",
        "        doc_type=doc_type,\n",
        "        clauses=extracted_clauses,\n",
        "        quiz=quiz,\n",
        "        classification=classification_result,\n",
        "        entities=entities,\n",
        "        answer=answer,\n",
        "        achievements=earned_achievements\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c259b70a",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/analyze_document\", methods=[\"POST\"])\n",
        "def analyze_document():\n",
        "    try:\n",
        "        file = request.files[\"document\"]\n",
        "        user_id = request.form.get(\"user_id\", \"anonymous\")\n",
        "\n",
        "        if file.filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
        "            image = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "            text = pytesseract.image_to_string(image)\n",
        "        else:\n",
        "            text = file.read().decode('utf-8', errors='ignore')\n",
        "\n",
        "        classification_result = classify_text_with_bert(text)\n",
        "        doc_type = DOCUMENT_TYPES[classification_result]\n",
        "        \n",
        "        extracted_clauses = extract_clauses(text)\n",
        "        \n",
        "        # Use specialized quiz generator for license agreements\n",
        "        if doc_type == \"License Agreement\":\n",
        "            quiz = generate_license_quiz(text, extracted_clauses)\n",
        "        else:\n",
        "            quiz = generate_advanced_quiz(text, extracted_clauses)\n",
        "        \n",
        "        entities = extract_entities(text)\n",
        "        \n",
        "        earned_achievements = save_to_firebase(text, quiz, extracted_clauses, doc_type, user_id)\n",
        "        \n",
        "        recent_scans = db.collection(\"scans\").where(\"user_id\", \"==\", user_id).order_by(\n",
        "            \"timestamp\", direction=firestore.Query.DESCENDING\n",
        "        ).limit(5).stream()\n",
        "\n",
        "        recent_scan_data = []\n",
        "        for scan in recent_scans:\n",
        "            scan_data = scan.to_dict()\n",
        "            scan_data[\"id\"] = scan.id\n",
        "            recent_scan_data.append(scan_data)\n",
        "            \n",
        "        return render_template(\n",
        "            \"results.html\",\n",
        "            doc_type=doc_type,\n",
        "            clauses=extracted_clauses,\n",
        "            quiz=quiz,\n",
        "            entities=entities,\n",
        "            user_id=user_id,\n",
        "            recent_scans=recent_scan_data,\n",
        "            achievements=earned_achievements\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return f\"Analysis error: {str(e)}\", 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a7db91c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/submit_quiz\", methods=[\"POST\"])\n",
        "def submit_quiz():\n",
        "    scan_id = request.args.get(\"scan_id\", \"\")\n",
        "    user_id = request.args.get(\"user\", \"anonymous\")\n",
        "\n",
        "    if not scan_id:\n",
        "        flash(\"Quiz not found.\", \"error\")\n",
        "        return redirect(url_for(\"index\"))\n",
        "\n",
        "    try:\n",
        "        scan_doc = db.collection(\"scans\").document(scan_id).get()\n",
        "        if not scan_doc.exists:\n",
        "            flash(\"Quiz not found.\", \"error\")\n",
        "            return redirect(url_for(\"index\"))\n",
        "\n",
        "        scan_data = scan_doc.to_dict()\n",
        "        quiz = scan_data.get(\"quiz\", [])\n",
        "        \n",
        "        if not quiz:\n",
        "            flash(\"No quiz questions found.\", \"error\")\n",
        "            return redirect(url_for(\"index\"))\n",
        "\n",
        "        score = 0\n",
        "        total_questions = len(quiz)\n",
        "        answers = []\n",
        "\n",
        "        # Create a mapping of question numbers to indices\n",
        "        question_map = {i+1: idx for idx, i in enumerate(range(len(quiz)))}\n",
        "        \n",
        "        for q_num, idx in question_map.items():\n",
        "            user_answer = request.form.get(f\"q{q_num}\", \"\").strip()\n",
        "            question = quiz[idx]\n",
        "            correct = False\n",
        "            \n",
        "            if user_answer.lower() == str(question.get(\"correct_answer\", \"\")).lower():\n",
        "                score += 1\n",
        "                correct = True\n",
        "            \n",
        "            answers.append({\n",
        "                \"question\": question.get(\"question\", \"\"),\n",
        "                \"user_answer\": user_answer,\n",
        "                \"correct_answer\": question.get(\"correct_answer\", \"\"),\n",
        "                \"correct\": correct\n",
        "            })\n",
        "\n",
        "        # Calculate percentage\n",
        "        percentage = (score / total_questions) * 100 if total_questions > 0 else 0\n",
        "        \n",
        "        # Save quiz results (without XP)\n",
        "        db.collection(\"quiz_results\").add({\n",
        "            \"user_id\": user_id,\n",
        "            \"scan_id\": scan_id,\n",
        "            \"score\": score,\n",
        "            \"total_questions\": total_questions,\n",
        "            \"percentage\": percentage,\n",
        "            \"answers\": answers,\n",
        "            \"timestamp\": datetime.utcnow().isoformat()\n",
        "        })\n",
        "\n",
        "        return render_template(\n",
        "            \"quiz_results.html\",\n",
        "            score=score,\n",
        "            total_questions=total_questions,\n",
        "            percentage=percentage,\n",
        "            answers=answers,\n",
        "            perfect_score=(score == total_questions),\n",
        "            user_id=user_id\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error submitting quiz: {str(e)}\")\n",
        "        flash(\"An error occurred while submitting your quiz.\", \"error\")\n",
        "        return redirect(url_for(\"index\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e86e7cd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/leaderboard\")\n",
        "def leaderboard():\n",
        "    users_ref = db.collection(\"users\").order_by(\"xp\", direction=firestore.Query.DESCENDING).limit(10)\n",
        "    users = []\n",
        "\n",
        "    for doc in users_ref.stream():\n",
        "        user_data = doc.to_dict()\n",
        "        user_id = user_data.get(\"user_id\", doc.id)\n",
        "        xp = user_data.get(\"xp\", 0)\n",
        "        level = xp // 100\n",
        "        scan_count = user_data.get(\"scan_count\", 0)\n",
        "        achievement_count = len(user_data.get(\"achievements\", []))\n",
        "    \n",
        "        users.append({\n",
        "            \"user_id\": user_id,\n",
        "            \"xp\": xp,\n",
        "            \"level\": level,\n",
        "            \"scan_count\": scan_count,\n",
        "            \"achievement_count\": achievement_count\n",
        "        })\n",
        "\n",
        "    current_user = request.args.get(\"user\")\n",
        "    current_user_rank = None\n",
        "\n",
        "    if current_user:\n",
        "        all_users = list(db.collection(\"users\").order_by(\"xp\", direction=firestore.Query.DESCENDING).stream())\n",
        "    \n",
        "        for i, user_doc in enumerate(all_users):\n",
        "            if user_doc.id == current_user or user_doc.to_dict().get(\"user_id\") == current_user:\n",
        "                current_user_rank = i + 1\n",
        "                break\n",
        "\n",
        "    return render_template(\n",
        "        \"leaderboard.html\",\n",
        "        users=users,\n",
        "        current_user=current_user,\n",
        "        current_user_rank=current_user_rank\n",
        "    )\n",
        "    \n",
        "# @app.route('/take_quiz')\n",
        "# def take_quiz():\n",
        "#     scan_id = request.args.get('scan_id', '')\n",
        "#     user_id = request.args.get('user', '')\n",
        "\n",
        "#     try:\n",
        "#         doc_ref = db.collection('scans').document(scan_id)\n",
        "#         scan_doc = doc_ref.get()\n",
        "    \n",
        "#         if scan_doc.exists:\n",
        "#             scan_data = scan_doc.to_dict()\n",
        "#             quiz_data = scan_data.get('quiz', [])\n",
        "#         else:\n",
        "#             flash(\"Scan not found\", \"error\")\n",
        "#             return redirect(url_for('index'))\n",
        "        \n",
        "#     except Exception as e:\n",
        "#         flash(f\"Error retrieving quiz: {str(e)}\", \"error\")\n",
        "#         return redirect(url_for('index'))\n",
        "        \n",
        "#     return render_template('quiz.html', scan_id=scan_id, user_id=user_id, quiz=quiz_data)\n",
        "\n",
        "# @app.route(\"/dashboard\")\n",
        "# def dashboard():\n",
        "#     user_id = request.args.get(\"user\", \"anonymous\")\n",
        "#     user_ref = db.collection(\"users\").document(user_id)\n",
        "#     user_data = user_ref.get().to_dict()\n",
        "#     xp = user_data[\"xp\"] if user_data else 0\n",
        "#     level = xp // 100\n",
        "#     progress = xp % 100\n",
        "#     return render_template(\"dashboard.html\", xp=xp, level=level, progress=progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d68a57f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route('/take_quiz')\n",
        "def take_quiz():\n",
        "    scan_id = request.args.get('scan_id')\n",
        "    user_id = request.args.get('user', 'anonymous')\n",
        "    \n",
        "    if not scan_id:\n",
        "        flash(\"No document specified for quiz\", \"error\")\n",
        "        return redirect(url_for('index'))\n",
        "\n",
        "    try:\n",
        "        scan_doc = db.collection('scans').document(scan_id).get()\n",
        "        if not scan_doc.exists:\n",
        "            flash(\"Document not found\", \"error\")\n",
        "            return redirect(url_for('index'))\n",
        "            \n",
        "        scan_data = scan_doc.to_dict()\n",
        "        quiz = scan_data.get('quiz', [])\n",
        "        \n",
        "        if not quiz:\n",
        "            flash(\"No quiz available for this document\", \"error\")\n",
        "            return redirect(url_for('index'))\n",
        "        \n",
        "        # Prepare quiz data with question numbers\n",
        "        quiz_with_numbers = []\n",
        "        for i, question in enumerate(quiz, 1):\n",
        "            question['number'] = i\n",
        "            quiz_with_numbers.append(question)\n",
        "            \n",
        "        return render_template('quiz.html', \n",
        "                            scan_id=scan_id, \n",
        "                            user_id=user_id, \n",
        "                            quiz=quiz_with_numbers)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving quiz: {str(e)}\")\n",
        "        flash(\"Error loading quiz\", \"error\")\n",
        "        return redirect(url_for('index'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "65ba4698",
      "metadata": {},
      "outputs": [],
      "source": [
        "@app.route(\"/dashboard\")\n",
        "def dashboard():\n",
        "    user_id = request.args.get(\"user\", \"anonymous\")\n",
        "    try:\n",
        "        user_ref = db.collection(\"users\").document(user_id)\n",
        "        user_data = user_ref.get().to_dict()\n",
        "        xp = user_data[\"xp\"] if user_data else 0\n",
        "        level = xp // 100\n",
        "        progress = xp % 100\n",
        "    except Exception as e:\n",
        "        print(f\"Firebase error, using mock data: {e}\")\n",
        "        # Mock data\n",
        "        xp = 150\n",
        "        level = 1\n",
        "        progress = 50\n",
        "    \n",
        "    return render_template(\"dashboard.html\", \n",
        "                         xp=xp, \n",
        "                         level=level, \n",
        "                         progress=progress,\n",
        "                         scan_count=5,  # Mock values\n",
        "                         quiz_completed=3,\n",
        "                         total_clauses=8,\n",
        "                         doc_types_analyzed=2,\n",
        "                         achievements=[],  # Empty array\n",
        "                         recent_scans=[])  # Empty array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b70985",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flask server is running in the background. Access it at http://127.0.0.1:5000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n",
            "127.0.0.1 - - [25/Apr/2025 10:53:30] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:53:30] \"GET /static/style.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:53:30] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
            "C:\\Users\\kowsh\\AppData\\Local\\Temp\\ipykernel_14060\\2247323509.py:45: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"timestamp\": datetime.utcnow().isoformat()\n",
            "d:\\legal-ed-platform\\.venv\\Lib\\site-packages\\google\\cloud\\firestore_v1\\base_collection.py:303: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
            "  return query.where(field_path, op_string, value)\n",
            "127.0.0.1 - - [25/Apr/2025 10:53:59] \"POST /analyze_document HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:53:59] \"GET /static/style.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:55:24] \"POST /analyze_document HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:55:24] \"GET /static/style.css HTTP/1.1\" 304 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:55:29] \"GET /take_quiz?scan_id=VVXlo6FEKPAHR390ekgN&user=anonymous HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [25/Apr/2025 10:55:29] \"GET /static/style.css HTTP/1.1\" 304 -\n"
          ]
        }
      ],
      "source": [
        "# Import threading to run Flask in a separate thread\n",
        "import threading\n",
        "\n",
        "def run_flask():\n",
        "    app.run(debug=False, use_reloader=False)  # Disable reloader and debug for notebook use\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "flask_thread = threading.Thread(target=run_flask)\n",
        "flask_thread.daemon = True  # This makes the thread exit when the notebook is closed\n",
        "flask_thread.start()\n",
        "\n",
        "print(\"Flask server is running in the background. Access it at http://127.0.0.1:5000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd297b52",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7fb3d2b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Firebase already initialized\n"
          ]
        }
      ],
      "source": [
        "# Firebase initialization with proper check\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        cred = credentials.Certificate(\"firebase_config.json\")  # Ensure this path is correct\n",
        "        firebase_admin.initialize_app(cred)\n",
        "        db = firestore.client()\n",
        "        print(\"Firebase initialized successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Firebase: {str(e)}\")\n",
        "        # Handle the error appropriately - maybe exit if Firebase is critical\n",
        "else:\n",
        "    print(\"Firebase already initialized\")\n",
        "    db = firestore.client()  # Still need to get the firestore client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e68ac28",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b91880",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be3b804d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
